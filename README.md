# CSCI3832_FinalProject

# NLP-Based Analysis and Generation of Song Lyrics Using Spotify Data

## Project Overview

This project aims to implement Natural Language Processing (NLP) models to classify songs into their respective genres and sentiments. We compare the accuracy of different models to determine which performs best and analyze the relationships between sentiment and genre. The project leverages the Spotify API and Genius API to extract lyrics and metadata.

## Key Tasks

1. **Text Classification:**
   - Classify song lyrics by sentiment (e.g., happy, sad, energetic).
   - Classify song lyrics by genre (e.g., rock, pop, rap).

2. **Model Comparison:**
   - Evaluate the performance of different NLP models (Encoder/Decoder, BERT, n-gram, LSTM).
   - Compare model accuracy and efficiency.

## Data Collection Process

### Spotify API Integration
This project collects song metadata and audio features using the Spotify Web API:

**Track Metadata Collection**: We use the Spotify API to collect basic information about tracks including name, artists, album, release date, and popularity.

### Genius API Integration

**Automatic Matching**: The system attempts to match Spotify tracks with their corresponding entries on Genius using artist name and track title.

**Lyrics Scraping**: Once a match is found, the lyrics are scraped from the Genius page using web scraping techniques with BeautifulSoup.

### Data Pipeline
The complete data collection process follows these steps:

1. Collect track IDs through playlists, searches, or genre recommendations
2. Fetch track metadata and audio features from Spotify
3. Match tracks to Genius entries
4. Scrape and process lyrics
5. Combine all data into a structured dataset

Note: Due to API rate limits, the collection process includes small delays between requests to avoid being blocked by either service.

## Project Goals

- Provide insights into how NLP can enhance music-related applications.
- Address challenges such as dataset bias and computational efficiency.
- Compare the performance of advanced models with basic models.

## Project Structure
```bash

project/
├── config/
│   └── config.py         # Configuration settings and API credentials
├── data/                 # Data storage directory
│   └── spotify_dataset.csv   # Default output location
├── src/
│   ├── collector.py      # Spotify data collection module
├── venv/                 # Virtual environment folder
│   ├──                   # Any additional files generated by venv
├── requirements.txt      # Project dependencies
├── .env                  # Environment variables (not in version control)
├── .env.example          # Environment variables example structure
├── .gitignore            
└── README.md
```

## Getting Started

1. **Clone the Repository:**
   ```bash
   git clone git@github.com:ima-mervin/CSCI3832_FinalProject.git
   ```
2. **Navigate to your project directory:**
   ```bash
   cd path/to/CSCI3832_FinalProject
   ```
3. **Environment Setup:**
   Create a ```.env``` file in the project root:
   ```bash touch.env```
4. **Setting up API credentials:**
   You can follow the instructions in ```.env.example``` to make your own ```.env```
   ```bash
   # Spotify API Credentials
   # Create these at https://developer.spotify.com/dashboard/
   SPOTIFY_CLIENT_ID=your_client_id_here
   SPOTIFY_CLIENT_SECRET=your_client_secret_here
   
   # Genius API Credentials
   # Create this at https://genius.com/api-clients/new
   GENIUS_ACCESS_TOKEN =your_genius_access_token
   
   # Default output file
   DEFAULT_OUTPUT_FILE = "your_path_to_data/data_file_name.csv"
   ```
5. **Create a virtual environment (this keeps your project dependencies isolated):**
   ```bash
   python -m venv venv
   ```
6. **Activate the virtual environment:**

   *On Windows:*
      ```bash
      venv\Scripts\activate
      ```
   *On macOS/Linux:*
      ```bash
      source venv/bin/activate
      ```
7. **Install the required packages:**
   ```bash
   pip install -r requirements.txt
   ```
8. **Running Scripts:**
   
  *Make sure your virtual environment is activated (you should see (venv) at the beginning of your command line)*
  
 *The script can be run in several different ways depending on what you want to accomplish, here are examples for a few data collection tasks you can run:*

   -**By Playlist**: To collect data from a specific playlist:```python -m src.collector --playlist "spotify_playlist"```
   
   -**By Search**: Search for playlists matching a term and collect data from the top result:```python -m src.collector --search "pop hits"```
   
   -**By Genre**: Collect recommended tracks based on specific genres:```python -m src.collector --genres "rock,pop,hip hop,jazz,country"```
   
   -**By Sentiment**:Collect recommended tracks based on specific genres:```python -m src.collector --sentiments "happy,sad,energetic,relaxed,angry"```
   
   -**Additional Options**: 
      - Limit the number of tracks::```--limit 50```
      - Specify output location: ```--output "data/custom_filename.csv"```

   ```bash
      #Example Commands
      # Collect from a specific playlist
      python -m src.collector --playlist "37i9dQZF1DXcBWIGoYBM5M"
      
      # Search for an indie playlist and limit to 30 tracks
      python -m src.collector --search "indie essentials" --limit 30
      
      # Get recommendations for dance music with custom output file
      python -m src.collector --genres "dance,electronic" --output "data/dance_tracks.csv"
      
   ```

9. **Viewing the Data:**
  Once the script has been successfully run, the data will be loaded into ```your_path/CSCI3832_FinalProject/data/spotify_dataset.csv``` or a custom path if that has been specified.

## Feature Extraction

The collector extracts the following data for each track:
```bash
- track_id
- track_name
- track_number
- disc_number
- duration_ms
- explicit
- popularity
- isrc
- preview_url
- track_url
- playlist_id
- playlist_name
- added_at
- added_by
- primary_artist
- all_artists
- artist_id
- artist_genre
- album_name
- album_id
- album_type
- album_release_date
- album_image_url
- lyrics

```
## Team Structure

The project is divided into three sub-teams:

- **Data Preprocessing and Classification:** Ima Mervin
- **Language Modeling Approaches:**
  - **Team Finetuning BERT:** Mia Ray and Mariana.
  - **Team Encoder/Decoder:** Gavin Hanville and Chloe.
 
## Acknowledgments

- This project uses the Spotify API for metadata collection and Genius API to scrape lyrics.
- Team members: Ima, Mia Ray, Mariana, Gavin Hanville, Chloe.
